Komputer dawniej: mózg elektronowy, elektroniczna maszyna cyfrowa, maszyna matematyczna[2]) – maszyna elektroniczna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego. Maszyna roku tygodnika „Time” w 1982 roku.

Mimo że mechaniczne maszyny liczące istniały od wielu stuleci, komputery w sensie współczesnym pojawiły się dopiero w połowie XX wieku, gdy zbudowano pierwsze komputery elektroniczne. Miały one rozmiary sporych pomieszczeń i zużywały kilkaset razy więcej energii niż współczesne komputery osobiste (PC), a jednocześnie miały miliardy razy mniejszą moc obliczeniową.

Małe komputery mogą zmieścić się nawet w zegarku i są zasilane baterią. Komputery osobiste stały się symbolem ery informatycznej i większość utożsamia je z „komputerem” właśnie. Najliczniejszymi maszynami liczącymi są systemy wbudowane sterujące najróżniejszymi urządzeniami – od odtwarzaczy MP3 i zabawek po roboty przemysłowe.

Komputer od typowego kalkulatora odróżnia zdolność wykonywania wielokrotnie, automatycznie powtarzanych obliczeń, według algorytmicznego wzorca zwanego programem, gdy tymczasem kalkulator może zwykle wykonywać tylko pojedyncze działania. Granica jest tu umowna, ponieważ taką definicję komputera spełniają też kalkulatory programowalne (naukowe, inżynierskie), jednak kalkulatory służą tylko do obliczeń numerycznych, podczas gdy nazwa komputer najczęściej dotyczy urządzeń wielofunkcyjnych.

Global Digital Divide1.png
Jakkolwiek istnieją mechaniczne urządzenia liczące, które potrafią realizować całkiem złożone programy, zazwyczaj nie zalicza się ich do komputerów. Warto jednak pamiętać, że prawzorem komputera jest abstrakcyjny model zwany maszyną Turinga, a pierwsze urządzenia ułatwiające obliczenia były znane w starożytności, np. abakus z 440 p.n.e.

W początkowym okresie rozwoju komputerów budowano komputery zerowej generacji na przekaźnikach i elementach mechanicznych.

Właściwie wszystkie współczesne komputery to maszyny elektroniczne. Próby budowania komputerów optycznych (wykorzystujących przełączniki optyczne), optoelektronicznych (połączenie elementów optycznych i elektronicznych), biologicznych (wykorzystujące wypreparowane komórki nerwowe) czy molekularnych (wykorzystujące jako bramki logiczne pojedyncze cząsteczki) są jeszcze w powijakach i do ich praktycznego zastosowania jest wciąż długa droga. Innym rodzajem komputera jest komputer kwantowy, którego układ przetwarzający dane wykorzystuje efekty fizyczne wynikające z mechaniki kwantowej.

W definicji komputera mieszczą się też urządzenia do przeliczania wartości reprezentowanych przez wielkość ciągłą (napięcie lub prąd elektryczny). Programowanie ich polega na określeniu toru przetwarzania sygnałów przełącznikami i ewentualnie określeniu stałych za pomocą potencjometrów. Komputery takie stosowano w połowie XX wieku i istniały nawet wyspecjalizowane w tym celu układy scalone. Obecnie nie opłaca się implementować algorytmów obliczeniowych w technice analogowej ze względu na niską cenę mikroprocesorów. Można jeszcze spotkać (np. w Rosji) analogowe komputery balistyczne służące do obliczania toru pocisków artyleryjskich, jednak i tam zastępuje się je komputerami cyfrowymi.

To, co odróżnia współczesne komputery od wszystkich innych maszyn, to możliwość ich programowania, czyli wprowadzenia do pamięci komputera listy instrukcji, które mogą być wykonane w innym czasie.

W większości przypadków instrukcje, które komputer wykonuje, są bardzo proste – dodawanie dwóch liczb, przeniesienie danych z jednego miejsca w inne, wyświetlenie komunikatu itd. Instrukcje te odczytywane są z pamięci komputera i zazwyczaj wykonywane są w tej samej kolejności, co w pamięci. Istnieją jednak instrukcje umożliwiające „skok” w pewne określone miejsce programu i wykonanie go z tego miejsca. Ponadto instrukcje skoku mogą być wykonane warunkowo, co umożliwia wykonanie różnych zestawów instrukcji w zależności od uzyskanych wcześniej wyników obliczeń. Ponadto istnieją instrukcje umożliwiające tworzenie podprogramów,

Programowanie można w pewnym stopniu przyrównać do czytania książki. W większości wypadków słowa odczytywane są po kolei, zdarzają się jednak momenty, gdy czytelnik wraca do wcześniejszego rozdziału lub omija nieciekawy fragment. Komputery mają możliwość wykonania pewnych instrukcji w pętli, dopóki nie zostanie spełniony jakiś warunek.

Można tu użyć przykładu człowieka próbującego zsumować kolejne liczby na kalkulatorze. Dodaje 1 + 2, do wyniku dodaje 3 itd. Przy próbie zsumowania 10 liczb nie stanowi to problemu, jednak już przy tysiącu po pierwsze zajmuje to bardzo dużo czasu, po drugie przy tak dużej ilości operacji istnieje duże prawdopodobieństwo błędu. Komputer z kolei wykona tę operację w ułamku sekundy, przy użyciu prostego programu: